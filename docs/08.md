# 目标
&nbsp; &nbsp; &nbsp; &nbsp; 上阶段cute-dl已经可以构建基础的RNN模型, 但是, 在一些应用场景下, 基础的RNN模型非常低效. 不论什么模型，都需要把输入数据表示为向量, 如果输入数据是非常稀疏的向量, 例如10000维one-hot编码的稀疏向量, 对于一个GRU层, 如果他的输出单元是64, 那么这个层的参数数量为: $10000 * 64 + 64 * 64 + 64=644160$, 如果把10000维稀疏向量转换成100维的稠密向量, 参数数量为:$100*64 + 64 * 64 + 64 = 10560$约是原来的1/64, 参数量的减少还是非常可观的。

&nbsp; &nbsp; &nbsp; &nbsp; RNN模型常用于文本分类任务。每个文本都可以看成是由词组成的词序列, 不论文本是什么语言, 都可以把这种语言中的所有词收集起来构建一个词汇表. 假设词汇表$V=\{w_1, w_2, ..., w_n\}$可以看成一个有n个词的集合, 现在为每个词分配一个唯一的ID, 词汇表可以表示为: $V=\{1=w_1, 2=w_2, ..., n=W_n\}$. 对于任意一个由词汇表中的词组成文本, 可以使用词汇表中词的ID, 把文本转换成一个整数的序列. 每个词ID都可以用one-hot编码转换成

&nbsp; &nbsp; &nbsp; &nbsp; 这个阶段会为cute-dl添加嵌入层, 把高维向量空间的稀疏向量嵌入到低维向量空间, 从而把高维稀疏向量转换成低维稠密向量。把一个向量X输入嵌入层之后得到向量E, E的值是不知道的, 可以把E看成待学习的参数在特定的任务中学习。

&nbsp; &nbsp; &nbsp; &nbsp; 如果把模型的输出看成下一个词出现的概率分布, 

# 文本预测的数学模型
## 贝叶斯后验概率模型

## 马尔可夫链模型

## 机器学习中的文本分类算法


## 深度学习中的数学含义


# 嵌入层设计
